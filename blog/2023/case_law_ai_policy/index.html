<!DOCTYPE html> <html lang="en"> <!-- Head --> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <!-- Metadata, OpenGraph and Schema.org --> <!-- Website verification --> <meta name="google-site-verification" content=""> <!-- Avoid warning on Google Chrome Error with Permissions-Policy header: Origin trial controlled feature not enabled: 'interest-cohort'. see https://stackoverflow.com/a/75119417 --> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <!-- Standard metadata --> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>To Advise or Not to Advise? Lawyers Weigh in on AI‚Äôs Legal Guidance | Inyoung Cheong</title> <meta name="author" content="Inyoung Cheong"> <meta name="description" content="Lawyers perspectives on when AI chatbots can appropriately provide legal guidance."> <meta name="keywords" content="Inyoung Cheong, AI, University of Washington, content moderation, free speech, legal research"> <!-- OpenGraph --> <meta property="og:site_name" content="Inyoung Cheong"> <meta property="og:type" content="website"> <meta property="og:title" content="Inyoung Cheong | To Advise or Not to Advise? Lawyers Weigh in on AI‚Äôs Legal Guidance"> <meta property="og:url" content="https://inyoungcheong.github.io/blog/2023/case_law_ai_policy/"> <meta property="og:description" content="Lawyers perspectives on when AI chatbots can appropriately provide legal guidance."> <meta property="og:image" content="https://inyoungcheong.github.io/assets/img/blog/inyoung-profile.png"> <meta property="og:locale" content="en"> <!-- Twitter card --> <meta name="twitter:card" content="summary"> <meta name="twitter:title" content="To Advise or Not to Advise? Lawyers Weigh in on AI‚Äôs Legal Guidance"> <meta name="twitter:description" content="Lawyers perspectives on when AI chatbots can appropriately provide legal guidance."> <meta name="twitter:image" content="https://inyoungcheong.github.io/assets/img/blog/inyoung-profile.png"> <!-- Bootstrap & MDB --> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <!-- Bootstrap Table --> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <!-- Fonts & Icons --> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="preconnect" href="https://fonts.googleapis.com"> <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin> <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Sans:wght@400;500;600;700&amp;family=Playfair+Display:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500&amp;family=Inter:wght@300;400;500;600;700&amp;family=Space+Mono:wght@400;700&amp;display=swap" rel="stylesheet"> <!-- Code Syntax Highlighting --> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/murphy.css" media="" id="highlight_theme_light"> <!-- Styles --> <link rel="shortcut icon" href="/assets/img/favicon.ico"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://inyoungcheong.github.io/blog/2023/case_law_ai_policy/"> <!-- Dark Mode --> </head> <!-- Body --> <body class="fixed-top-nav sticky-bottom-footer"> <!-- Header --> <header> <!-- Nav Bar --> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Inyoung Cheong</a> <!-- Navbar Toggle --> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <!-- Other pages --> <li class="nav-item "> <a class="nav-link" href="/about/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <!-- Blog / Musings (after other pages) --> <li class="nav-item active"> <a class="nav-link" href="/blog/">Musings<span class="sr-only">(current)</span></a> </li> </ul> </div> </div> </nav> <!-- Scrolling Progress Bar --> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <!-- Content --> <div class="container mt-5"> <!-- _layouts/post.html --> <div class="post"> <header class="post-header"> <h1 class="post-title">To Advise or Not to Advise? Lawyers Weigh in on AI‚Äôs Legal Guidance</h1> <p class="post-meta">October 31, 2023</p> <p class="post-tags"> <a href="/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Our team was selected by OpenAI for their <a href="https://openai.com/blog/democratic-inputs-to-ai" rel="external nofollow noopener" target="_blank">Democratic Inputs to AI</a> project. Through this support, we pioneered participatory research establishing a case-based approach for professional AI advice systems. <a href="http://social.cs.washington.edu/case-law-ai-policy/" rel="external nofollow noopener" target="_blank">Our project website</a> and <a href="https://arxiv.org/abs/2311.10934" rel="external nofollow noopener" target="_blank">our paper</a> selected for NeurIPS 2023 MP2 Workshop details the process. As part of this work, I led an expert workshop eliciting perspectives on the appropriateness of legal guidance from AI chatbots. This blog post summarizes key insights on ensuring responsible, ethical AI assistance in the legal domain.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <!-- Fallback to the original file --> <img src="/assets/img/blog/lawyer_ai.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> figure: Inyoung Cheong </div> <p>As AI-based chatbots become increasingly sophisticated, people are turning to robots for expert knowledge ‚Äî medical advice, legal counsel, financial planning ‚Äî once largely inaccessible or unaffordable. Now, people utilize AI-powered chatbots to get personalized guidance and customized answers to their most pressing questions. Law is one such high demand area. Despite how regularly people encounter legal issues ‚Äî rental agreements, divorce filings, and noise disputes with neighbors, for example ‚Äî lawyers are notoriously expensive.</p> <p>However, there are many valid concerns around chatbots providing legal advice. To name a few, inaccuracy in the guidance could lead to detrimental real-world outcomes. Additionally, potential data breaches pose privacy risks given the sensitive nature of legal matters. There are also worries about bias and unfair recommendations, as well as lack of interpretability around how the chatbot arrives at suggestions. Further concerns include misuse or abuse of the legal advice provided, especially when not constrained by professional ethics and conduct standards lawyers are held to.</p> <p>In this sense, EU AI law (draft) puts AI systems used for ‚ÄúAssistance in legal interpretation and application of the law‚Äù into the high-risk category. While the convenience and accessibility of chatbots for legal guidance is appealing, these systems must be developed thoughtfully to address the many risks accompanying such a powerful application.</p> <p>There has been very little research specifically examining the factors that determine the appropriateness of AI systems providing professional guidance. Prior scholarship has discussed AI advice mainly in broad, speculative terms rather than conducting in-depth studies grounded in real-world use cases and expert perspectives. This research gap motivated our qualitative study engaging domain experts, legal professionals. By eliciting lawyers‚Äô insights on sample cases, we aimed to develop a detailed, nuanced understanding of when AI recommendations are viewed as proper versus irresponsible.</p> <h2 id="research-design">Research Design</h2> <p>We conducted an in-depth study to understand when legal AI advice is viewed as appropriate by experts like lawyers. Our goal was to build a detailed, contextual understanding of the appropriateness of AI legal advice grounded in the perspectives of experts like lawyers who provide such counsel professionality.</p> <blockquote> <p>Question: When is it appropriate for AI systems to give advice in the legal domain?</p> </blockquote> <h3 id="data-collection">Data Collection</h3> <p>We collected sample ‚Äúseed cases‚Äù representing real user queries needing legal advice. For example:</p> <blockquote> <p>‚ÄúI run a popular online mobile game with microtransactions and collect user data per our terms. We run ads too. What should our legal strategy cover?‚Äù</p> </blockquote> <p>We then presented these cases to legal professionals along with hypothetical AI responses.</p> <h3 id="participatory-workshops">Participatory Workshops</h3> <p>We then conducted six remote participatory workshops with 20 legal experts, including active lawyers in the UK and the US, law professors, and two law students. We presented the seed cases along with hypothetical AI responses based on patterns seen in state-of-the-art, free for use, and public-facing models like GPT-3.</p> <p>Response templates included:</p> <table> <thead> <tr> <th>Template Name</th> <th>Description</th> <th>Example Response (Legal Advice)</th> </tr> </thead> <tbody> <tr> <td>Content violation</td> <td>Displays a warning message that the user‚Äôs input violates the AI‚Äôs content policy.</td> <td>This content may violate our content policy. If you believe this to be in error, please submit your feedback‚Äîyour input will aid our research in this area.</td> </tr> <tr> <td>Refuse to answer</td> <td>Avoids providing a response to the input and advises the user to seek professional advice instead.</td> <td>As an AI model, I am not a substitute for consulting with a trained professional. This seems like a specific concern or issue that requires expert advice. It‚Äôs always advisable to speak with a professional in the relevant field.</td> </tr> <tr> <td>High-level answer without facts</td> <td>Provides a response that answers the input in broad strokes, stating advice rather than facts.</td> <td>I am not a lawyer, but I can provide some general information about possible legal strategies that might be used in a situation like this. 1. Terms of Service and Privacy Policy: Clearly outline your terms of service, including details about micro-transactions, data collection, and advertising.</td> </tr> <tr> <td>Specific answer with facts</td> <td>Provides a detailed response that cites specific facts relevant to the input.</td> <td>I am not a lawyer, but I can provide some information about specific legal strategies that may be applied in a situation like this. 1. Compliance with Applicable Laws and Regulations: Laws like the Children‚Äôs Online Privacy Protection Act (COPPA) and the California Consumer Privacy Act (CCPA) may be relevant.</td> </tr> <tr> <td>Ask a follow-up question</td> <td>Responds with a question requesting more information.</td> <td>To help you with this, I will need some additional information. Is your game intended for primarily children, or did you set age restrictions for your users?</td> </tr> </tbody> </table> <p>Semi-structured discussions focused on key factors shaping the perceived appropriateness and risks of different AI advisor response styles for 2-3 seed cases that experts chose. Experts took turns presenting factors that they took into account while envisioning the most desirable AI responses. After each workshop, we compiled the identified factors for analysis.</p> <p>Re: popular online mobile game prompt, key dimensions considered by experts for that case include:</p> <ul> <li>Location of operation (whether the mobile game operates in the states having privacy law)</li> <li>Ad providers‚Äô data collection practices (are ad providers also collecting data)</li> <li>Involvement of minors (whether there are users who fall under a certain age)</li> <li>Nature of data (what kind of user information is being collected?)</li> <li>Terms of service (language and terminology used in the terms of service)</li> </ul> <h2 id="key-factors-identified">Key Factors Identified</h2> <p>Analysis of discussions with lawyers revealed numerous key dimensions that influence suitable AI guidance. Key factors spanned categories shown below:</p> <table> <thead> <tr> <th>Category</th> <th>Factors Considered</th> </tr> </thead> <tbody> <tr> <td>User Attributes</td> <td>Sophistication, Geography, Identity, Status, Reliability, Agency</td> </tr> <tr> <td>User Query</td> <td>Scope, Stakes, Information Sufficiency, Desired Response Type, Judgment Needed</td> </tr> <tr> <td>AI Capabilities</td> <td>Accuracy, Context-Awareness, Interpretability, Novelty</td> </tr> <tr> <td>Legal Aspects</td> <td>Ambiguity, Complexity, Standard Practices</td> </tr> <tr> <td>Potential Impact</td> <td>User Emotions, Justice System</td> </tr> </tbody> </table> <h3 id="differing-views-on-the-capabilities-of-ai">Differing Views on the Capabilities of AI.</h3> <p>Opinions differ on the capabilities of current AI systems. Some believe AI can contextualize information and even surpass lawyers in processing huge amounts of legal data. However, others remain skeptical due to the risk of inaccuracies. There was consensus that the need for AI advice depends partly on AI capabilities advancing responsibly and transparently. However, even assuming that AI systems could be made completely accurate and secure, concerns would still exist around AI systems providing actionable recommendations.</p> <h3 id="chatbots-arent-bound-by-ethics-rules">Chatbots Aren‚Äôt Bound by Ethics Rules.</h3> <p>Experts indicate that human lawyers are bound by ethics rules (e.g., confidentiality, competent representation, conflicts of interest, malpractice) and can face disciplinary action if they violate them. Chatbots don‚Äôt have legal or ethical duties. Hypothetically, they can represent both sides, share information with others without consent, or give bad advice. Without oversight mechanisms, chatbots lack accountability for improper guidance. This heightens risks in relying on AI legal advice.</p> <h3 id="legal-information-is-different-from-advice">Legal information is different from advice.</h3> <p>Experts largely concurred that discussing general legal information is appropriate, much like search engines already provide. However, personalized advice requires professional judgment. Participants emphasized keeping responses as non-binding information statements (‚Äúif this, then that‚Äù), rather than opinions on users‚Äô specific cases. A participant believes the AI should refuse to answer a question like ‚Äúcould I win a lawsuit‚Äù altogether, since determining something like that involves nuanced legal analysis and human judgment that the AI cannot replicate.</p> <p>Professionals emphasized that AI should focus on addressing purely informational queries lacking situational specifics. For instance, discussing high-level legal principles, rights and procedures is considered as ‚Äúgeneral knowledge‚Äù and poses less risk than advising actions for a user‚Äôs nuanced case. This aligns with court rulings differentiating neutral education from individualized recommendations reserved for licensed attorneys, although the distinction between two concepts is somewhat blurry.</p> <h3 id="a-chatbot-should-indicate-its-speculative-responses-may-be-incomplete">A chatbot should indicate its speculative responses may be incomplete.</h3> <p>Experts generally agree that AI systems cannot make a comprehensive analysis because of inherently insufficient facts and details. Attempting complex legal analysis with limited information risks generating misleading or speculative outputs. A participant gave an example of a DACA recipient charged with driving under intoxication, which could potentially result in deportation as a crime of moral turpitude. The recipient‚Äôs DACA status could completely change the strategy for plea bargaining in this scenario. However, it is unrealistic to expect an AI system to inquire about DACA status whenever asked about a drunken driving charge. Therefore, AI responses should acknowledge that they do not provide a complete picture. The appropriate response when presented with vague hypothetical scenarios seems to be recognizing that there are insufficient facts provided, and additional details could significantly alter the analysis and outcomes. Making firm legal judgments without a full understanding of a situation‚Äôs specifics is problematic.</p> <h3 id="asking-users-follow-up-questions-was-generally-encouraged">Asking users follow-up questions was generally encouraged.</h3> <p>While acknowledging the limitations of making definitive legal conclusions with incomplete information, experts largely agreed that AI systems should have the ability to ask users follow-up questions to clarify hypothetical situations presented. Since initial prompts from laypeople often lack legally relevant facts, asking clarifying questions can help the chatbot distill the most legally meaningful information for further analysis and improve the user‚Äôs ability to ‚Äúask a better question.‚Äù</p> <p>However, some experts were not inclined toward AI systems retrieving extensive personal details from users due to potential security concerns. They cautioned that collecting excessive information could increase vulnerability if confidentiality is compromised. In this regard, experts underscored that users must be clearly and transparently informed about data handling policies and consent to any collection of sensitive information (‚ÄúProtections in place so that confidential information isn‚Äôt reused or leaked.‚Äù).</p> <h3 id="chatbot-conversations-are-not-confidential-risking-harms-on-non-users">Chatbot conversations are not confidential, risking harms on non-users.</h3> <p>Unlike private attorney conversations, chatbot interactions are ‚Äúessentially public,‚Äù able to be shared widely online. This publicity poses risks around legal advice ‚Äútaken out of context.‚Äù For instance, if a hate crime suspect asked about their legal defense, the chatbot response may include what ‚Äúcould offend some groups.‚Äù While attorneys can tailor guidance to clients privately, chatbots cannot adapt publicly visible responses.</p> <h3 id="certain-legal-domains-are-better-suited-for-machine-guided-decisions">Certain legal domains are better suited for machine-guided decisions.</h3> <p>All legal domains are not created equal. It‚Äôs important to recognize that established business practices allow professionals to make routine decisions easily. Experts were more inclined to give detailed answers to informational questions like identifying states with low corporate tax rates or the legality of using lie detectors during the interrogation, which has the ‚Äúobjective answer‚Äù in the legal world. Experts found answering these clearly informational questions analogous to Google search results. Although stakes were high, some experts agreed to advise on states allowing medically-assisted death for permanent diseases.</p> <p>However, there are complex and ambiguous areas like tax law where attorneys frequently have to make judgment calls based on experience. Also, many experts strongly cautioned against relying solely on AI in criminal cases, where plea bargains consider nuanced, subjective factors like a judge‚Äôs interests and religion. Having quality legal representation is significant from due process principles.</p> <p>In domains with great complexity and subjectivity, it is found to be not practical or advisable to depend entirely on AI legal assistance. The human judgment of an attorney remains critical for handling nuance and weighing various factors. While AI can provide information and analysis, human expertise is still vital in areas like criminal law or other fields requiring deep judgment calls. Users should be aware of the limitations of AI in handling subjective or highly ambiguous legal situations. Expert counsel remains key in these contexts.</p> <h3 id="experts-distinguish-between-ai-for-lawyers-and-ai-for-the-general-public">Experts distinguish between AI for lawyers and AI for the general public.</h3> <p>While we approached this workshop considering public-facing use cases, experts noted meaningful distinctions between AI systems aimed at assisting legal professionals versus those intended for use by the general public. They expressed that AI designed as a ‚Äúco-pilot‚Äù for lawyers may be viewed more positively, as it can help reduce human error while lawyers retain responsibility (‚ÄùUsing machines to help or do us do our job; I think it‚Äôs seen as generally positive.‚Äù). AI could be valuable for lawyers by streamlining ‚Äúintake processes‚Äù and honing the specifics of legal issues, given appropriate confidentiality protections.</p> <p>However, public-facing legal AI systems impose greater risks on layperson users who lack legal expertise. Unlike enterprise solutions with balanced liability sharing, consumer legal AI products may have one-sided indemnification clauses leaving users vulnerable. Without the context to properly evaluate AI limitations, the public may develop an undue reliance. Therefore, experts emphasized the need for careful precautions around AI intended for public consumption, including transparent terms of service, clear explanation of risks, and reasonable limitations on use cases to avoid exploiting user expectations.</p> <h3 id="ai-systems-should-respect-users-agency">AI systems should respect users‚Äô agency.</h3> <p>Experts emphasize that the user retains autonomy; the AI is meant to augment human decision-making by providing additional information, not replace accountable judgment. When providing analysis or recommendations, AI systems designed for high-stakes fields like law should respect that human discretion still dominates suitability considerations over algorithmic intelligence. As such, the AI‚Äôs outputs should avoid emotional manipulation or pressure tactics that could improperly sway users‚Äô objective, reasoned choices.</p> <p>Furthermore, introducing an ‚Äúemotional quotient‚Äù risk making unsupported assumptions about people‚Äôs internal states and motivations. This could lead to unfair profiling or inappropriate advice with real consequences, especially without human oversight. It can note potential risks or caution about harmful outcomes but should couch these as uncertainties rather than absolutes. By respecting human agency and discretion, AI systems can enhance legal advice without undermining users‚Äô self-determination. The goal is empowering informed decisions, not imposing prescribed paths.</p> <p>While AI cannot (or should not) entirely replicate or replace a lawyer‚Äôs judgment, our study elucidates how to create transparent AI assistants that know when to defer to human experts. With thoughtful design, AI can expand access to legal knowledge while avoiding reliance on imperfect machine intelligence for decisions with serious consequences. But only through considering the multitude of human, technological and regulatory dimensions revealed by experts can AI truly complement legal professionals in an ethical manner.</p> <h2 id="contribution">Contribution</h2> <p>This research makes several notable contributions towards developing more trustworthy and human-centered AI systems. First, it pioneers a new methodology for participatory technology ethics, engaging diverse stakeholders in evaluating AI responses based on real-world cases. This collaborative assessment approach represents a significant evolution beyond speculative principles or theoretical frameworks.</p> <p>Second, the insights generated from this process make tangible progress towards actionable guidelines for imbuing AI systems with sound judgement aligned to professional and community values. By grounding evaluations in practical examples and focusing on nuanced criteria of appropriateness, the findings provide targeted guidance for improving reliability and transparency.</p> <p>Finally, this research lays the foundation for a scalable model of participatory AI ethics that can be expanded across other professional domains. The methods and insights establish a framework for incorporating human-centered design principles through cooperative evaluation of AI systems. This has the potential to greatly enhance user trust and satisfaction by creating technologies that better serve their needs and align with their values.</p> <p>This work makes pioneering steps toward ensuring AI is developed responsibly and ethically with consideration for its real-world impacts on people and society. The participatory assessment process, context-specific findings, and potential for transferring the approach to other fields represent significant contributions in the pursuit of trustworthy AI.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <!-- Adds related posts to the end of an article --> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2026/llm-higher-ed/">LLM Lit Review Experiment with Claude Opus 4.6</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/tools/">4 Essential Tools I Used to Redesign My Website.</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/newsite/">Website renewal ü§©</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/jeonmindong/">Get togehter, Jeonmin-dong!</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/maria-schneider/">Maria Schneider; A Lost Star</a> </li> </div> </div> <!-- Footer --> <!-- JavaScripts --> <!-- jQuery --> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <!-- Bootsrap & MDB scripts --> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <!-- Masonry & imagesLoaded --> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <!-- Medium Zoom JS --> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <!-- Bootstrap Table --> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <!-- Load Common JS --> <script src="/assets/js/no_defer.js"></script> <script defer src="/assets/js/common.js"></script> <script defer src="/assets/js/copy_code.js" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <!-- MathJax --> <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <!-- Global site tag (gtag.js) - Google Analytics --> <script async src="https://www.googletagmanager.com/gtag/js?id=G-KB3EZ5YVPD"></script> <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){ window.dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-KB3EZ5YVPD');
  </script> <!-- Scrolling Progress Bar --> <script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script> </body> </html>